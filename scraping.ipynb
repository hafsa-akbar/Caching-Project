{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping to download images per category in any given news website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_categories(url):\n",
    "    # news categories (and associated href) fetched via nav components\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    categories = []\n",
    "    navs = soup.find_all('nav')\n",
    "\n",
    "    for nav in navs:\n",
    "        for link in nav.find_all('a'):\n",
    "            category = link.get_text(strip=True)\n",
    "            category_url = link.get('href')\n",
    "            if category and category_url:\n",
    "                categories.append((category, urljoin(url, category_url)))\n",
    "\n",
    "    return categories\n",
    "\n",
    "def create_directories(base_url, categories):\n",
    "    # create the following dir struct; outputs > base website > categories\n",
    "    base_dir = os.path.join(\"outputs\", urlparse(base_url).netloc)\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "    \n",
    "    for category, _ in categories:\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            os.makedirs(category_dir)\n",
    "\n",
    "    return base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(img_url, save_dir, img_name):\n",
    "    try:\n",
    "        if not img_url.startswith('data:'):\n",
    "            response = requests.get(img_url)\n",
    "            img_data = response.content\n",
    "            img = Image.open(BytesIO(img_data))\n",
    "            width, height = img.size\n",
    "\n",
    "            # Only save images larger than 100x100 pixels\n",
    "            if width >= 100 and height >= 100:\n",
    "                with open(os.path.join(save_dir, img_name), 'wb') as img_file:\n",
    "                    img_file.write(img_data)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "def download_images(category_url, save_dir):\n",
    "    # download all images of a particular category\n",
    "    try:\n",
    "        response = requests.get(category_url)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f'Error fetching the category URL: {e}')\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    images = soup.select('img[src]')\n",
    "\n",
    "    # parallising the downloads to make it faster\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        for i, img in enumerate(images):\n",
    "            img_url = img.get('src')\n",
    "            if img_url and not img_url.startswith('data:'):\n",
    "                img_url = urljoin(category_url, img_url)\n",
    "                img_name = f'image_{i}.jpg'\n",
    "                futures.append(executor.submit(download_image, img_url, save_dir, img_name))\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the base url to any news website for which you want to download images (for every category) \n",
    "\n",
    "Tried for: thegaurdian, time.com, tribune.pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images for every category:  71%|███████▏  | 30/42 [00:27<00:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1061bf740>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619b5b0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11083f3d0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1061bf330>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619b560>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619a110>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619a200>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1061bff60>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x106581d50>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x106583510>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1061991c0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1108c8360>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x106198d10>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107929490>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1065db790>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x111388a40>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1108c8f90>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619a110>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x111388f40>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1108c9bc0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images for every category:  76%|███████▌  | 32/42 [00:28<00:07,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11082bdd0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107c5aac0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107c59cb0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x105f60f40>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107ced990>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11082b7e0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x105f61990>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11082bba0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11082b650>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x10619b560>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107ced990>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x105f608b0>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x105f61620>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x107cecf90>\n",
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x11082b880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images for every category:  95%|█████████▌| 40/42 [00:31<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading the image: cannot identify image file <_io.BytesIO object at 0x1113e29d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images for every category: 100%|██████████| 42/42 [00:31<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.bbc.com/' #change this\n",
    "categories = get_news_categories(base_url)\n",
    "\n",
    "if not categories:\n",
    "    print(\"No categories found.\")\n",
    "    \n",
    "base_dir = create_directories(base_url, categories)\n",
    "for category, category_url in tqdm(categories, desc='Downloading images for every category'):\n",
    "    category_dir = os.path.join(base_dir, category)\n",
    "    download_images(category_url, category_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding images to GPT-4o (chat completion module) for their similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first supply the 'training' similarity scores in the form of a matrix for the images given in the train folder<br>The matrix for n images is an n x n *symmetric* matrix with (nC2) comparisons\n",
    "e.g,\n",
    "|       | img0  | img1  | \n",
    "|-------|-------|-------|\n",
    "| **img0** | 1.0   | x  | \n",
    "| **img1** | x  | 1.0   | \n",
    "\n",
    "\n",
    "This similarity matrix serves as the few shot example training for the LLM<br>Feel free to change/add to the training images in the train folder and redefine the training similarity matrix\n",
    "\n",
    "**Note: api calls charged per usage ~0.5 usd for every 5 image comparisons (5x5 simlarity matrix - 10 comparisons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'image_(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "train_images = sorted(\n",
    "    [os.path.join('train', f) for f in os.listdir('train') if f.endswith(('jpg', 'jpeg', 'png'))],\n",
    "    key=extract_number\n",
    ")\n",
    "\n",
    "# define your similarity score labels for training\n",
    "similarity_scores = [\n",
    "    [1.0, 0.75, 0.3, 0.3],\n",
    "    [0.75, 1.0, 0.4, 0.4],\n",
    "    [0.3, 0.4, 1.0, 0.95],\n",
    "    [0.3, 0.4, 0.95, 1.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('api_key')\n",
    "api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### You can find the api key on the slack channel or use your own api key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def load_image_as_base64(image_path):\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "few_shot_examples = []\n",
    "\n",
    "# create few shot training with sample question answering\n",
    "for i in range(len(train_images)):\n",
    "    for j in range(i + 1, len(train_images)):\n",
    "        base64_img1 = load_image_as_base64(train_images[i])\n",
    "        base64_img2 = load_image_as_base64(train_images[j])\n",
    "        \n",
    "        few_shot_examples.extend([\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img1}\"}\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img2}\"}\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Question: Compute semantic similarity score for the above pair of images.\\nAnswer: {similarity_scores[i][j]}\"\n",
    "            }\n",
    "        ])\n",
    "\n",
    "# system role to specify the answer content - feel free to prompt engineer here\n",
    "system_message = [\n",
    "    {\"role\": \"system\", \"content\": \"You need to assign similarity scores to pairs of images based on the main content and context of the image focusing on actions, emotions, and overall meaning and NOT on specific visual details such as colors or specific objects. When answering, ONLY give a numeric similarity score. Follow these examples:\"},\n",
    "    {\"role\": \"user\", \"content\": few_shot_examples}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(image_paths):\n",
    "    # compute similarity scores given the prompt above for all combinations of all images passed\n",
    "    user_messages = []\n",
    "    \n",
    "    for i in range(len(image_paths)):\n",
    "        for j in range(i + 1, len(image_paths)):\n",
    "            base64_img1 = load_image_as_base64(image_paths[i])\n",
    "            base64_img2 = load_image_as_base64(image_paths[j])\n",
    "            \n",
    "            user_messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Compare these two images for semantic similarity.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img1}\"}},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img2}\"}}\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    responses = []\n",
    "    for message in tqdm(user_messages, desc=\"Processing image pairs\"):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=system_message + [message],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        time.sleep(1)\n",
    "        responses.append(response.choices[0].message.content)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(image_paths, similarity_scores):\n",
    "    n = len(image_paths)\n",
    "    similarity_matrix = [[1 if i == j else 0 for j in range(n)] for i in range(n)]\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            similarity_matrix[i][j] = similarity_scores[idx]\n",
    "            similarity_matrix[j][i] = similarity_scores[idx]\n",
    "            idx += 1\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def process_categories(base_dir):\n",
    "    category_folders = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    matrices = {}\n",
    "\n",
    "    for category_dir in category_folders:\n",
    "        image_paths = sorted(\n",
    "            [os.path.join(category_dir, f) for f in os.listdir(category_dir) if f.endswith(('jpg', 'jpeg', 'png'))],\n",
    "            key=extract_number\n",
    "        )\n",
    "        if len(image_paths) < 2:\n",
    "            continue\n",
    "\n",
    "        similarity_scores = compare_images(image_paths)\n",
    "        similarity_matrix = make_matrix(image_paths, similarity_scores)\n",
    "        \n",
    "        matrices[category_dir] = similarity_matrix\n",
    "\n",
    "    with open(f'{base_dir}.json', 'w') as json_file:\n",
    "        json.dump(matrices, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the similairty matrix for each category in the test folder and saving the results to test.json<br>\n",
    "Feel free to add to / remove from the test folder - **I first generate images using the web scraping module above and then only pick 2-3 categories with 4-5 images each to test because of the cost of api usage**\n",
    "\n",
    "***** Please only run the below cell for *new* images added to the test folder because previous results have already been computed and kept in the test.json file - rerunning for the same images will only cost more without any benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_test = 'test'\n",
    "process_categories(folder_to_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
