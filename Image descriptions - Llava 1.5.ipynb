{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing dependenices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U transformers==4.37.2\n",
    "!pip3 install -q bitsandbytes==0.41.3 accelerate==0.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import BitsAndBytesConfig, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=model_id)#, model_kwargs={\"quantization_config\": quantization_config})\n",
    "\n",
    "# quantization only supported if GPU available\n",
    "# pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_image_files(path):\n",
    "    image_files = {}\n",
    "    try:\n",
    "        for website in os.listdir(path):\n",
    "            website_path = os.path.join(path, website)\n",
    "            if os.path.isdir(website_path):\n",
    "                image_files[website] = [\n",
    "                    i for i in os.listdir(website_path)\n",
    "                    if not (i.endswith('.js') or i.endswith('.css') or i.endswith('.svg') or i.endswith('.gif') or i.endswith('.csv'))\n",
    "                ]\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return image_files\n",
    "\n",
    "\n",
    "# Process images and generate captions\n",
    "\n",
    "def process_images(image_files, date_path, output_path):\n",
    "    for key, img_list in image_files.items():\n",
    "        path = os.path.join(date_path, key)\n",
    "        print(f\"{key} {len(img_list)} images are to be processed\")\n",
    "\n",
    "        output_csv = os.path.join(output_path, f'{key}_llava.csv')\n",
    "        print(output_csv)\n",
    "\n",
    "        with open(output_csv, 'w') as f:\n",
    "            f.write(\"Index,Image,Description\\n\")    \n",
    "\n",
    "        for idx, image_file in tqdm(enumerate(img_list), total=len(img_list), desc=f\"Processing {key}\"):\n",
    "            try:\n",
    "                # Open image\n",
    "                image = Image.open(os.path.join(path, image_file)).convert('RGB')\n",
    "\n",
    "                # Define prompt\n",
    "                prompt = \"USER: <image>\\nDescribe this image in detail. Be sure to focus on what the image represents rather than specific visuals like colors and shapes.\\nASSISTANT:\"\n",
    "\n",
    "                # Generate caption using Llava\n",
    "                outputs = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "                generated_caption = outputs[0][\"generated_text\"]\n",
    "\n",
    "                # Process the generated caption\n",
    "                intermediate_output = ''.join((generated_caption.split('ASSISTANT:')[1].strip()).split(','))\n",
    "                final_output = ''.join(intermediate_output.split('\\n'))\n",
    "\n",
    "                # Write to CSV\n",
    "                with open(output_csv, 'a') as f:\n",
    "                    f.write(f\"{idx + 1},{image_file},{final_output}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images for both directories\n",
    "image_files_23 = collect_image_files('dataset/23_July_News')\n",
    "image_files_24 = collect_image_files('dataset/24_July_News')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating descriptions for images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(image_files_23, 'dataset/23_July_News', 'results')\n",
    "process_images(image_files_24, 'dataset/24_July_News', 'results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
